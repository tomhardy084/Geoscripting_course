{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geoscripting Exercise 14\n",
    "#### Team Chantalle_Tom\n",
    "#### Date: 25-01-2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, datetime, time, folium, json, string, csv, psycopg2, pprint, urllib\n",
    "import numpy as np\n",
    "from twython import Twython\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from time import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an \"output\" and a \"data\" folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.stat(\"output\")\n",
    "except:\n",
    "    os.mkdir(\"output\")\n",
    "    \n",
    "try:\n",
    "    os.stat(\"data\")\n",
    "except:\n",
    "    os.mkdir(\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Set up a twython connection to the twitter app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codes to access twitter API. \n",
    "APP_KEY = \"IguYRmMdLHICCCRmQnxf2a5FJ\"\n",
    "APP_SECRET = \"P47HzAzm5mxmxMVLyx8018ago2Yg90DuvKxivwsvqbJnf1XC2a\"\n",
    "OAUTH_TOKEN = \"956457001936179201-HLLsWkifl5qbnlLV6hV58P1EQ9xSJs9\"\n",
    "OAUTH_TOKEN_SECRET = \"9Ry0ZYgYah7g1vSPZUpjhAF8BaKyMTeftIc0boQ9hsKGf\"\n",
    "\n",
    "# initiating Twython object\n",
    "twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Make a twitter search query with hashtag WURcampustour and a maximum count of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "search_results = twitter.search(q = [\"#WURcampustour\"], count = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create an array from chosen information from the search result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#parsing out\n",
    "twitter_data = [] # create empty array\n",
    "for tweet in search_results[\"statuses\"]:\n",
    "    username =  tweet['user']['screen_name']\n",
    "    tweettext = tweet['text']\n",
    "    \n",
    "    tweet_data = [username, tweettext]\n",
    "    \n",
    "    if tweet['place'] != None:\n",
    "        full_place_name = tweet['place']['full_name']\n",
    "        place_type =  tweet['place']['place_type']\n",
    "        tweet_data.extend([full_place_name, place_type])\n",
    "        \n",
    "    if tweet['coordinates'] != None:\n",
    "        coor = tweet['coordinates']['coordinates']\n",
    "        tweet_data.extend(coor)\n",
    "        \n",
    "    twitter_data += [tweet_data]\n",
    "\n",
    "del(twitter_data[0],twitter_data[5],twitter_data[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Store the data into a csv file\n",
    "The file is stored in the data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## store it as a csv file \n",
    "\n",
    "output_file = 'data/result_' + datetime.now().strftime('%Y%m%d-%H%M%S') + '.csv'\n",
    "\n",
    "f = open(output_file, 'w')\n",
    "\n",
    "with f:\n",
    "    writer = csv.writer(f)\n",
    "    for row in twitter_data:\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  Extract the neccesary information from the twitter data (username, message, and coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an np.array from the twitter data\n",
    "twitter_data_array = np.array(twitter_data)\n",
    "\n",
    "# Extract tweet text\n",
    "tweet_text = twitter_data_array[:,1]\n",
    "\n",
    "# define function to extract coordinates in proper format for plotting map with folium\n",
    "def tweet_coor(array):\n",
    "    tweet_coor = []\n",
    "    for elem in array:\n",
    "        elem = sorted([elem[0].astype(float), elem[1].astype(float)], reverse = True)\n",
    "        tweet_coor += [elem]\n",
    "    return(tweet_coor)\n",
    "\n",
    "# extract coordinates array and make the proper plotting format out of it with defined function\n",
    "tweet_coor_array = twitter_data_array[:,4:6]\n",
    "tweet_coor_list = tweet_coor(tweet_coor_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Create a map with the locations of the tweets\n",
    "The map is stored as an html in the output folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "WUR_map = folium.Map(location=[51.985, 5.665],\n",
    "                   tiles='openstreetmap', zoom_start = 16)\n",
    "\n",
    "for i in range(len(tweet_coor_list)):\n",
    "    folium.Marker(tweet_coor_list[i], popup = tweet_text[i], icon = folium.Icon(color=\"green\", icon=\"info-sign\")).add_to(WUR_map)\n",
    "\n",
    "WUR_map.save('output/WUR_map.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
